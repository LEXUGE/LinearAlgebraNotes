% Created 2020-05-18 Mon 21:24
% Intended LaTeX compiler: pdflatex
\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{grffile}
\usepackage{longtable}
\usepackage{wrapfig}
\usepackage{rotating}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{textcomp}
\usepackage{amssymb}
\usepackage{capt-of}
\usepackage{hyperref}
\hypersetup{colorlinks=true,linkcolor=blue}
\usepackage[margin=0.5in]{geometry}
\author{Harry Ying}
\date{}
\title{Linear Algebra Notes}
\hypersetup{
 pdfauthor={Harry Ying},
 pdftitle={Linear Algebra Notes},
 pdfkeywords={},
 pdfsubject={},
 pdfcreator={Emacs 26.3 (Org mode 9.1.9)},
 pdflang={English}}
\begin{document}

\maketitle
\tableofcontents \clearpage
\section{Chapter 1}
\label{sec:org8585f56}
\subsection{\(\S\) 1}
\label{sec:org03503c6}
\subsubsection{Notes}
\label{sec:orgfbc572f}
A generic vector space \(V\) is not a field because there is no definition of \(v^{-1}\) for some \(v\in V\), fulfilling not the definition of a field.\\
\begin{enumerate}
\item \textbf{Pg. 4 Proof of \((-1)v=v\)}
\label{sec:org13055dd}
$$\begin{aligned}
(-1)v+v&=(-1)v+1\cdot v\\
&=(-1+1)v\\
&=v+(-v)
\end{aligned}$$
Thus, \((-1)v=-v\).
\item \textbf{Pg. 6 Proof of SP 3}
\label{sec:orga2af5dc}
$$\begin{aligned}
(xA)\cdot B&=\sum\limits_{i=1}^{n}(xa_i) b_{i}\\
&=\sum\limits_{i=1}^{n}x(a_i b_{i})\\
&=x\sum\limits_{i=1}^{n} a_i b_{i}\\
&=x(A\cdot B)\\
A\cdot (xB)&=\sum\limits_{i=1}^{n}a_i (xb_{i})\\
&=\sum\limits_{i=1}^{n}x(a_i b_{i})\\
&=x\sum\limits_{i=1}^{n} a_i b_{i}\\
&=x(A\cdot B)
\end{aligned}$$
\item \textbf{\textbf{Pg. 7}}
\label{sec:org5c4500e}

Upper one:
$$\begin{aligned}
(A+B)^2&=(A+B)\cdot (A+B)\\
&=(A+B)\cdot A+(A+B)\cdot B && \text{Use SP 2}\\
&=A^2+B\cdot A+A\cdot B+B^2 && \text{Use SP 1}\\
\end{aligned}$$
Bottom one:
Since \(K\) is a field, all \textbf{VS} s regarding summation or product of functions are actually closed on \(K\). By applying field axioms, \(V\) is then a vector space over \(K\).
\item \textbf{\textbf{Pg. 9}}
\label{sec:orgbc0dac1}

\label{org087c9e9}
Let \(a_1=(u_1+w_1),a_2=(u_2+w_2)\). Both of them \(\in (U+W)\).\\
Since \(U,W\) are subspaces of \(V\), \(U,W\in V\). Thus, \(a_1,a_2 \in V\) as \(u_1,w_1,u_2,w_2\in V\), moreover, \((U+W)\subset V\).\\
\(a_1+a_2=(u_1+u_2)+(w_1+w_2)\in (U+W)\) \\
\(ca_1=c(u_1+w_1)=(cu_1)+(cw_1)\in (U+W)\) \\
Since \(O\in U\) and \(O\in W\), \(O=O+O\in (U+W)\). Thus, \((U+W)\) is a subspace of \(V\).
\end{enumerate}
\subsubsection{Exercises}
\label{sec:org67a4466}
\begin{enumerate}
\item \textbf{Exercise 1}
\label{sec:org0122d1f}
Let \(v\in{} V\), \(c[v+(-v)]=cv+c(-v)=cv+(-c)v=v\cdot{}0=v\cdot{}(1-1)=v+(-v)=O\)
\item \textbf{Exercise 2}
\label{sec:org7a37c4a}
Since \(c\not = 0\)
$$\begin{aligned}
O&=cv+[-(cv)]\\
cv&=cv+[-(cv)]\\
O&=-(cv)\\
\frac{-1}{c}\cdot O &= (-c)v\cdot \frac{-1}{c}\\
\frac{-1}{c}\cdot (v-v) &= v\\
\frac{-1}{c}\cdot v+ \frac{1}{c}\cdot v &= v\\
v\cdot (1-1)&=v\\
v-v&=v\\
O&=v
\end{aligned}$$
\item \textbf{Exercise 3}
\label{sec:orgb372df7}

\(\forall g\in V, (g+f)(x) = g(x)+f(x) = f(x)+g(x) = (f+g)(x) \Rightarrow g+f = f+g\).\\
If \(O+u = u\), \((O+u)(x) = O(x)+u(x)= u(x)\). Therefore, \(O(x)=0\).
\item \textbf{Exercise 4}
\label{sec:org271def6}
$$\begin{aligned}
v+w&=O\\
v+w&=v+(-v)\\
w&=-v
\end{aligned}$$
\item \textbf{Exercise 5}
\label{sec:org4ee75e9}
$$\begin{aligned}
v+w&=v\\
v+(-v)+w&=v+(-v)\\
O+w&=O
\end{aligned}$$
Since \(\forall u, O+u=u\), we have \(w=O\).
\item \textbf{Exercise 6}
\label{sec:org20cd58c}

Let \(W=\{B| B\cdot A_{1}=O\ \text{and}\ B\cdot A_2=O\}\). Specifically, it is clear that \(O\in W\) as \(O\cdot A = \sum\limits_{i=1}^{n} b_i a_i=\sum\limits_{i=1}^{n} 0\times a_i=0\).\\
Let \(v_1,v_2 \in W\) such that \(v_1\cdot A_1=0\), \(v_1\cdot A_2=0\), \(v_2\cdot A_1=0\), \(v_2\cdot A_2=0\). Thus,
$$\begin{aligned}
(v_1+v_2)\cdot A_1&=v_1\cdot A_1+v_2\cdot A_1\\
&=O+O\\
&=O\\
[c(v_1+v_2)]\cdot A_1&=(cv_1+cv_2)\cdot A_1\\
&=(cv_1)\cdot A_1+(cv_2)\cdot A_1\\
&=c(v_1\cdot A_1+v_2\cdot A_1)\\
&=cO\\
&=O
\end{aligned}$$.
It is easy to show for \(A_2\) then. Therefore, \((v_1+v_2)\in W\).
\item \textbf{Exercise 7}
\label{sec:org4fe550f}
Same to apply as Exercise 6.
\item \textbf{Exercise 8}
\label{sec:org0c4f4aa}

Name the set as \(W\).
\begin{enumerate}
\item Proof
\label{sec:org7ecd2b4}

\(v_1+v_2=(x_1+x_2,y_1+y_2), x_1+x_2=y_1+y_2 \Rightarrow (v_1+v_2)\in W\) \\
\(cv=(cx,cy), cx=cy \Rightarrow cv\in W\) \\
\(O=(0,0)\in W\)
\item Proof
\label{sec:orgb2b8a5a}
See Part (a).
\item Proof
\label{sec:org928cb69}
Same technique as in Part (a).
\end{enumerate}
\item \textbf{Exercise 9}
\label{sec:org62693ca}
See Exercise 8.
\item \textbf{Exercise 10}
\label{sec:org3182060}

For \(U\cap W\), let \(v_1,v_2\in U\cap W\). Since \(v_1, v_2\in U\) and \(U\) is a subspace, \(v_1+v_2\in U\). In same way, we can see that \(v_{1}+v_2\in W\). Thus, \(v_1+v_2\in U\cap W\).\\
Since \(v_1\in U\), \(cv_1\in U\). Also, it shows \(cv_1\in W\) in the same way. Thus, \(cv_{1}\in U\cap W\).
Because \(U, W\) are subspaces, \(O\in U\) and \(O\in W\). Thus, \(O\in U\cap W\). Therefore, \(U\cap W\) is a subspace.\\
Refer to the \hyperref[org087c9e9]{note part} for proof for \(U+W\).
\item \textbf{Exercise 11}
\label{sec:org2b77c9f}
Since \(L\) is a field, \textbf{VS1, VS3, VS4, VS8} are established under field axioms, and multiplication and addition are closed in \(L\). For \textbf{VS5, VS6, VS7}, they are all valid as \(K\subset L\). \(O\) is simply \(0\), and \(1\cdot u=u\) is  established in \(L\).
\item \textbf{Exercise 12}
\label{sec:org3fd5496}

For \(x,y\in K\), we have\\
\(x+y=a_1+b_1\sqrt{2}+a_2+b_2\sqrt{2}=(a_1+a_2)+(b_1+b_2)\sqrt{2}\). Since \(a_1,b_1,a_2,b_2\in \mathbb{Q}\), \((a_1+a_2),(b_1+b_2)\in\mathbb{Q}\). Thus, \(x+y\in K\).\\
\(xy=(a_1 a_2+ 2b_1 b_2)+(a_2 b_1 + a_1 b_2)\times \sqrt{2}\). Since \(a_1,b_1,a_2,b_2\in \mathbb{Q}\), \((a_1 a_2+ 2b_1 b_2),(a_2 b_1 + a_1 b_2)\in\mathbb{Q}\). Thus, \(x+y\in K\).\\
\(-x=-a+-b\sqrt{2}\). Since \(a,b\in\mathbb{Q}\), \(-a,-b\in\mathbb{Q}\). Thus, \(-x\in K\).\\
If \(a+b\sqrt{2}\not = 0\), \(a,b\not = 0\), and \(a-b\sqrt{2}\not = 0\). Thus, \(x^{-1}=\frac{1}{a+b\sqrt{2}}=\frac{a-b\sqrt{2}}{a^2-2b^{2}}=\frac{a}{a^2-2b^2}-\frac{b}{a^2-2b^2}\sqrt{2}\). It is easy to see that \textbf{new} \(a,b\in\mathbb{Q}\) as \(a,b\in\mathbb{Q}\). Thus, \(x^{-1}\in K\).
Specifically, if \(a=b=0\), \(0\in\mathbb{Q}\). If \(a=1,b=0\), \(1\in\mathbb{Q}\).\\
Thus, \(K\) is a field.
\item \textbf{Exercise 13}
\label{sec:org8672eae}
Same technique as Exercise 12.
\item \textbf{Exercise 14}
\label{sec:org451df8f}
Same technique as Exercise 12.
\end{enumerate}
\subsection{\(\S\) 2}
\label{sec:org4cba6f3}
\subsubsection{Notes}
\label{sec:orgfd5ef8f}
\label{org07ba6ef}
Another quite helpful equivalent of definition of linear independence is that (stated following without loss of generality)
$$\forall a_1\not = 0,a_1 v_1\not =\sum\limits_{i=2}^n a_i$$
Here is the \emph{proof} of equivalence between above statement and definition of linear independence.\\
Since \(a_1\not = 0\),
$$\begin{aligned}
v_1&\not =\sum\limits_{i=2}^n \frac{a_i}{a_1}v_i\\
O&\not = -v_1+\sum\limits_{i=2}^n \frac{a_i}{a_1}v_i\\
\lambda O&\not = (-\lambda)v_1 + \sum\limits_{i=2}^n \frac{\lambda a_i}{a_1}v_i && \lambda\in K \text{ and }\lambda\not = 0\\
O&\not = (-\lambda)v_1 + \sum\limits_{i=2}^n \frac{\lambda a_i}{a_1}v_i && \lambda\in K \text{ and }\lambda\not = 0\\
\end{aligned}$$
\(\lambda\) and \(a_i\) could be arbitrary, thus from above we could conclude that \(a'_1 v_1\not =\sum\limits_{i=2}^n a'_i\) if and only if all \(a'=0\), which is the definition of linear independence.\\
Also, another point that worth paying attention to is that generators could be \textbf{linear dependent}. This is true because you could put arbitrary vectors at the end of a basis of a vector space and just set coefficients for these extraneous vectors when it is producing new linear combinations.
\subsubsection{Exercises}
\label{sec:orgcca110e}
\begin{enumerate}
\item \textbf{Exercise 1}
\label{sec:orge886843}
Using result from \hyperref[org1577da4]{\textbf{Exercise 4}}, easy to prove.
\item \textbf{Exercise 2}
\label{sec:orgf051324}
\begin{enumerate}
\item \((1,-1)\)
\label{sec:org9990ca1}
\item \((\frac{1}{2},\frac{3}{2})\)
\label{sec:org34a282e}
\item \((1,1)\)
\label{sec:org868d702}
\item \((3,2)\)
\label{sec:org031b5df}
\end{enumerate}
\item \textbf{Exercise 3}
\label{sec:org17af3fe}
\begin{enumerate}
\item \((\frac{1}{3},-\frac{1}{3},\frac{1}{3})\)
\label{sec:orgc6b7f4d}
\item \((1,0,1)\)
\label{sec:org4809b75}
\item \((\frac{1}{3},-\frac{1}{3},-\frac{2}{3})\)
\label{sec:org44b7aca}
\end{enumerate}
\item \textbf{Exercise 4}
\label{sec:org4cdfa23}
\label{org1577da4}

Following set of equations is an equivalent of \(x(a,b)+y(c,d)=O\),
$$\begin{aligned}
ax+cy&=0 && (1)\\
bx+dy&=0 && (2)\\
\end{aligned}$$
$$\begin{aligned}
(1)\times d-(2)\times c\Rightarrow (ad-cb)x+cdy-cdy &= 0\\
(ad-cb)x&=0\\
\end{aligned}$$
For \(ad-cb\not =0\) part, clearly we shall see that \(x=0\) as \((ad-cb)x=0\). Plugging \(x\) back to \((1)\), we get \(y=0\). Thus, two vectors are linear independent.\\
For \(ad-cb=0\) part, we need to prove that \(x(a,b)+y(c,d)=O\) has solution other than \(x=y=0\).\\
First, suppose \(a,b,c,d\not = 0\). Since \(ad-cb=0\), \(x\in \mathbb{R}\). By applying technique, we could also show \(y\in \mathbb{R}\). Thus, \((a,b),\ (c,d)\) are linear independent.\\
If \(a,b,c,d\not = 0\) does \textbf{NOT} hold. Without lose of generality (for all the possibilities, \(a,d\) and \(c.b\) are interchangeable), consider following scenarios in a \(xy\) -plane,
\begin{enumerate}
\item \(a=0,c=0\)
\label{sec:org7bdbe35}

If \(a=c=0\), \(x,y\in \mathbb{R}\) in \((1)\). Because the \((2)\) is a line in the plane, there must exist some \(x,y\not = 0\).
\item \(a=0,b=0,c=0\)
\label{sec:orgb2866c8}

Same argument as above, despite the line represented by \((2)\) is a little bit peculiar (it is \(y=0\)).
\item \(a=0,d=0,c=0\)
\label{sec:orgb9217e8}

Same argument as the first, despite the line represented by \((2)\) is a little bit peculiar (it is \(x=0\)).
\item \(a=0,d=0,b=0,c=0\)
\label{sec:org996cd08}

Both \((1), (2)\) represent the whole plane, thus, \(x,y\in \mathbb{R}\).
\end{enumerate}
\item \textbf{Exercise 5,6}
\label{sec:orge679342}

To correctly understand how could functions be elements(vectors) in vector space, we need to understand that function \(f:S\rightarrow K\) is essentially a set of pairs \((s,k),\forall s\in S\). Functions have scalar multiplication and addition defined.\\
\(f+g\) is defined as \(\{(s,f(s)+g(s))|s\in S\}\), and \(cf, c\in K\) is defined as \(\{(s,c\cdot f(s))|s\in S\}\).\\
It is easy to verify that \(V\) of every \(f:S \rightarrow K\) is a vector space over \(K\). Particularly, \(O\) for \(V\) is \(\{(s,0)|s\in S\}\). So like other vector spaces, linear dependence is \textbf{about}
$$f_{sum}=\sum\limits_{i=1}^n a_if_i=O$$
Since right-hand-side of the equation is \(\{(s,0)|s\in S\}\), we can say that \(\forall v\in V, f_sum (s)=0\). This is useful in solving problems in \textbf{Exercise 5} and \textbf{Exercise 6}.\\
For example, we need to show that \(f(s)=1\) and \(g(s)=t\) are linear independent. This means that we need to consider following equation,
$$af+bg=O$$
which is an equivalent of
$$\forall t,a+bt=0$$
Above conversion is quite helpful since we could put in arbitrary \(t\) and the equation should holds. Thus, we could put in particular values of \(t\) to \textbf{construct} set of equations to show that \(a=b=0\). For example, here we plug in \(t=0\), then \(a=0\), and if we plug back \(a=0\) into original equation with \(t=0\) again, \(b=0\).\\
This method could be used throughout \textbf{Exercise 5,6}.
\item \textbf{Exercise 7}
\label{sec:org63b32f4}
\((3,5)\)
\item \textbf{Exercise 8}
\label{sec:orgbc59fed}
\emph{\textbf{Calculus involved, not doing now.}}
\item \textbf{Exercise 9}
\label{sec:orgefb2fe6}
$$\begin{aligned}
\sum\limits_{i=1}^{r} [a_i\cdot (A_i\cdot \sum\limits_{j=i+1}^{r}A_{j})]&=O && \text{All vectors are mutually perpendicular}\\
&=\sum\limits_{i=1}^{r} [(a_i\cdot A_i)\cdot \sum\limits_{j=i+1}^{r}A_{j}]\\
\end{aligned}$$
Since \(\forall A\in \{A_i\}, A\not = O\), it is only possible that every \(a\) is \(0\). Thus, \({A_i}\) are linearly independent.
\item \textbf{Exercise 10}
\label{sec:org9ab5003}

Since \(v,w\) are linear dependent, for
$$nv+mw=O$$
at least one of \(n,m\not =0\).
Consider following scenarios, we can see that there would be \(a=0\) or \(a=-\frac{n}{m}\).
\begin{enumerate}
\item \(n=0,m\not =0 \Rightarrow w=O\)
\label{sec:org8ce15c5}
\item \(n\not =0,m =0 \Rightarrow v=O\).
\label{sec:orgfddc121}
This contradicts with \(v\not =O\) in problem. Thus, this is impossible.
\item \(n\not = 0, m\not =0 \Rightarrow w=\frac{-n}{m}v\)
\label{sec:orgdfd9b21}
\end{enumerate}
\end{enumerate}
\subsection{\(\S\) 3}
\label{sec:org7782f83}
\subsubsection{Notes}
\label{sec:orgd6a7b71}
This subsection comprises a lot of concise proofs. But in conclusion, we need to know that
$$\begin{aligned}
\text{Basis}&\Leftrightarrow \text{Maximal linear independent vector set} && \text{proof at }\bold{Theorem 3.1}\\
\text{Basis}&\Leftrightarrow \text{Maximal linear indpendent vector set} \Rightarrow \text{Generators} && \text{proof at }\bold{Theorem 2.2}\\
\text{Generators} &\nRightarrow \text{Basis} && \text{Generators are not always linear independent.}
\end{aligned}$$
Thus, all possible bases of a vector space \(V\) are of one and only one possible number of elements, which is equal to the one of maximal independent vector set.
\subsection{\(\S\) 4}
\label{sec:org56c71e6}
\subsubsection{Notes}
\label{sec:org5fd2c5d}
\emph{Proof} for $$\dim (U\times W)=\dim U+\dim W$$
Because \(\forall u\in (U\times W) ,(O_u+O_w)+u=u+(O_u+O_w)=u\). Thus, by definition, \(O=(O_u,O_w)\).\\
Let \(A=\{u_i\}\) be a basis of \(U\) and \(B=\{w_i\}\) be a basis of \(W\). Note the dimension of \(U,W\) as \(n,m\) respectively. Let $$C=\{(u_i,0)|u_i\in A\}\cup\{(0,w_i)|w_i\in B\}$$
Since there would be no intersection between two sets being union above, the number of elements in \(C\) is \(n+m\).
If we could show that \(C\) is a basis of \(U\times W\), then we could show the original statement.\\
First we need to show that all elements in \(C\) is linear independent. This means \(a_i\in K,c_i\in C\)
$$\sum\limits_{i=1}^{n+m}a_i c_i$$
if and only if all the \(a_i=0\).\\
Because multiplication by scalar and addition for \(U\times W\) is defined componentwise, we shall see that (if we keep the "order" of elements in \(C\) as \(A\) and \(B\) are merged)
$$\begin{aligned}
\sum\limits_{i=1}^{n}a_i u_i&=O_u\\
\sum\limits_{i=n+1}^{n+m}a_i w_i&=O_w
\end{aligned}$$
Since both \(A\) and \(B\) are basis of \(U\) and \(W\) respectively, all the \(a_i\) should be \(0\).\\
Now, we need to show that \(C\) generates \(U\times W\). Since \(A\) and \(B\) are basis of \(U\) and \(W\) respectively,
$$\forall (a,b)\in (U\times W), \exists f_i,g_i\in K:\sum\limits_{i=1}^n f_i u_i=a \text{ and } \sum\limits_{i=1}^m g_i w_i=b $$
Thus, by setting set of scalar for "order"-kept \(C\) as \(\{f_i\}\cup \{g_i\}\), it is easy to see that it generates \(U\times W\).\\
Therefore, we see that
$$\dim (U\times W)=\dim U+\dim W$$
and
$$\{(u_i,0)|u_i\in A\}\cup\{(0,w_i)|w_i\in B\}$$
is a basis for \(U\times W\).\\
\subsubsection{Exercises}
\label{sec:orga7bdb8f}
\begin{enumerate}
\item \textbf{Exercise 1}
\label{sec:orgd9e05e9}

For the first part, we need to show that \(\forall v\in V, \exists \text{ unique } u\in U, w\in W: v=u+w\). Since \((2,1)\) and \((0,1)\) are linear independent, they are a basis of \(V=\mathbb{R}^2\). This means
$$\forall v\in V, \exists \text{ unique } a,b\in K: v=a\cdot (2,1)+b\cdot (0,1)$$
Thus, just set \(u=a\cdot (2,1)\) and \(w=b\cdot (0,1)\), and we have proved it.\\
It is same for \((2,1)\) and \((1,1)\).
\item \textbf{Exercise 2}
\label{sec:orgf2b8f66}

Since \((1,0,0), (1,1,0), (0,1,1)\) are linear independent, we obtain that
$$\forall v\in V, \exists \text{ unique } a,b,c\in K: v=a\cdot (1,0,0)+b\cdot (1,1,0)+ c\cdot (0,1,1)$$
Set \(u=a\cdot (1,0,0)\) and \(w=b\cdot (1,1,0)+ c\cdot (0,1,1)\), it would be proved.
\item \textbf{Exercise 3}
\label{sec:orgf87cd50}
According to argument provided \hyperref[org07ba6ef]{here}, \(\forall c\in K,cA\not =B\) means that \(A,B\) are linear independent. Also, according to \textbf{Theorem 3.4}, they are a basis of \(\mathbb{R}^2\).\\
Based on the similar argument in \textbf{Exercise 1}, second part could be proved.
\item \textbf{Exercise 4}
\label{sec:org28c7826}
See notes
\end{enumerate}
\end{document}
